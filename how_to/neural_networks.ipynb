{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basecells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Squeeze Class\n",
    "\n",
    "### `Squeeze` Class\n",
    "\n",
    "The `Squeeze` class is a PyTorch module that performs the squeezing operation on a tensor. It removes dimensions with size 1 from the input tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Squeeze(nn.Module):\n",
    "    def __init__(self, from_dim: int = 0):\n",
    "        super().__init__()\n",
    "        self.from_dim = from_dim\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usage:**\n",
    "\n",
    "You can use the `Squeeze` module to remove dimensions with size 1 from a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3936573004.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    output_tensor = squeeze(input_tenso\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the Squeeze module\n",
    "squeeze = Squeeze(from_dim=1)\n",
    "\n",
    "# Example input tensor with dimensions (1, 3, 4)\n",
    "input_tensor = torch.randn(1, 3, 4)\n",
    "\n",
    "# Apply the squeeze operation\n",
    "output_tensor = squeeze(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## LinearCell Class\n",
    "\n",
    "### `LinearCell` Class\n",
    "\n",
    "The `LinearCell` class is a PyTorch module that represents a fully connected layer preceded by optional batch normalization and followed by an activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class LinearCell(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int | None,\n",
    "        out_features: int,\n",
    "        activation: nn.Module | None = nn.ReLU(),\n",
    "        batch_norm: bool = True,\n",
    "        ...\n",
    "    ):\n",
    "        super().__init__()\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usage:**\n",
    "\n",
    "You can use the `LinearCell` module to create fully connected layers with optional batch normalization and activation functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the LinearCell module\n",
    "linear_cell = LinearCell(in_features=64, out_features=128, activation=nn.ReLU(), batch_norm=True)\n",
    "\n",
    "# Example input tensor with dimensions (batch_size, in_features)\n",
    "input_tensor = torch.randn(32, 64)\n",
    "\n",
    "# Apply the linear cell\n",
    "output_tensor = linear_cell(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ConvCell Class\n",
    "\n",
    "### `ConvCell` Class\n",
    "\n",
    "The `ConvCell` class is a PyTorch module that represents a convolutional layer preceded by optional batch normalization and followed by an activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ConvCell(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int | None,\n",
    "        out_channels: int,\n",
    "        kernel_size: int = 3,\n",
    "        activation: nn.Module | None = nn.ReLU(),\n",
    "        batch_norm: bool = True,\n",
    "        ...\n",
    "    ):\n",
    "        super().__init__()\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Usage:**\n",
    "\n",
    "You can use the `ConvCell` module to create convolutional layers with optional batch normalization and activation functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the ConvCell module\n",
    "conv_cell = ConvCell(in_channels=3, out_channels=64, activation=nn.ReLU(), batch_norm=True)\n",
    "\n",
    "# Example input tensor with dimensions (batch_size, channels, height, width)\n",
    "input_tensor = torch.randn(32, 3, 128, 128)\n",
    "\n",
    "# Apply the convolutional cell\n",
    "output_tensor = conv_cell(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResConvCell Class\n",
    "\n",
    "### `ResConvCell` Class\n",
    "\n",
    "The `ResConvCell` class is a subclass of the `ConvCell` class and represents a residual convolutional layer. It performs a convolution operation, followed by an addition operation with the input tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResConvCell(ConvCell):\n",
    "    def __init__(self, *args, padding=\"same\", **kwargs):\n",
    "        super().__init__(*args, padding=\"same\", **kwargs)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Usage:**\n",
    "\n",
    "You can use the `ResConvCell` module to create residual convolutional layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the ResConvCell module\n",
    "residual_conv_cell = ResConvCell(in_channels=64, out_channels=64, activation=nn.ReLU(), batch_norm=True)\n",
    "\n",
    "# Example input tensor with dimensions (batch_size, channels, height, width)\n",
    "input_tensor = torch.randn(32, 64, 128, 128)\n",
    "\n",
    "# Apply the residual convolutional cell\n",
    "output_tensor = residual_conv_cell(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this documentation, we have explained the purpose of the provided code and described the usage of the `Squeeze`, `LinearCell`, `ConvCell`, and `ResConvCell` classes for building neural network architectures in PyTorch. These classes are useful for creating layers with different configurations, including batch normalization, activation functions, and convolutional operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `LinearNet` Class\n",
    "\n",
    "### `LinearNet` Class\n",
    "\n",
    "The `LinearNet` class is a PyTorch sequential neural network module designed for creating feedforward neural networks with linear layers. It supports customizable hidden layers with activation functions and batch normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Sequence\n",
    "\n",
    "class LinearNet(torch.nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int | None,\n",
    "        out_features: int,\n",
    "        hidden_features: Sequence[int] = (16,),\n",
    "        activation: torch.nn.Module = torch.nn.ReLU(),\n",
    "        out_activation: torch.nn.Module | None = None,\n",
    "        batch_norm: bool = True,\n",
    "        bias: bool = True,\n",
    "        device: torch.device | None = None,\n",
    "        dtype: torch.dtype | None = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usage:**\n",
    "\n",
    "You can use the `LinearNet` class to create feedforward neural networks with linear layers, including hidden layers with activation functions and batch normalization if desired.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ConvNet` Class\n",
    "\n",
    "### `ConvNet` Class\n",
    "\n",
    "The `ConvNet` class is a PyTorch sequential neural network module designed for creating convolutional neural networks (CNNs). It supports customizable convolutional layers, hidden layers with activation functions, batch normalization, and optional residual connections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Sequence\n",
    "\n",
    "class ConvNet(torch.nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int | None,\n",
    "        out_channels: int,\n",
    "        kernel_size: int = 3,\n",
    "        hidden_channels: Sequence[int] = (16,),\n",
    "        activation: torch.nn.Module = torch.nn.ReLU(),\n",
    "        batch_norm: bool = True,\n",
    "        residual_connections: bool = False,\n",
    "        groups: int = 1,\n",
    "        bias: bool = True,\n",
    "        device: torch.device | None = None,\n",
    "        dtype: torch.dtype | None = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Usage:**\n",
    "\n",
    "You can use the `ConvNet` class to create CNNs with customizable convolutional layers, hidden layers, activation functions, batch normalization, and optional residual connections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ConvEncoder` Class\n",
    "\n",
    "### `ConvEncoder` Class\n",
    "\n",
    "The `ConvEncoder` class is a PyTorch sequential neural network module designed for encoding data using convolutional layers followed by linear layers. It supports customizable architecture with convolutional and linear layers, activation functions, batch normalization, and optional residual connections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Sequence\n",
    "\n",
    "class ConvEncoder(torch.nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int | None,\n",
    "        out_features: int,\n",
    "        kernel_size: int = 3,\n",
    "        hidden_channels: Sequence[int] = (16, 16),\n",
    "        hidden_features: Sequence[int] = (16,),\n",
    "        activation_conv: torch.nn.Module = torch.nn.ReLU(),\n",
    "        activation_linear: torch.nn.Module = torch.nn.ReLU(),\n",
    "        residual_connections: bool = False,\n",
    "        groups: int = 1,\n",
    "        batch_norm: bool = True,\n",
    "        bias: bool = True,\n",
    "        device: torch.device | None = None,\n",
    "        dtype: torch.dtype | None = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usage:**\n",
    "\n",
    "You can use the `ConvEncoder` class to create neural networks for encoding data using convolutional and linear layers. It allows customization of architecture, activation functions, batch normalization, and optional residual connections.\n",
    "\n",
    "In this documentation, we have explained the purpose of the provided code and described the usage of the `LinearNet`, `ConvNet`, and `ConvEncoder` classes for creating various types of neural networks. These classes are useful for building and customizing deep learning models for different tasks, such as image classification or feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lazymodules\n",
    "## `_LazyParamDepMixin` Class\n",
    "\n",
    "### `_LazyParamDepMixin` Class\n",
    "\n",
    "The `_LazyParamDepMixin` class is a base mixin class that is used to dynamically set the behavior and class of a PyTorch module based on the input data during runtime. It also handles the initialization of module parameters based on the input shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class _LazyParamDepMixin:\n",
    "    def set_class_behaviour(self, param: Any):\n",
    "        \"\"\"Set the behavior of the preinitialized module inferred from the input.\"\"\"\n",
    "        ...\n",
    "\n",
    "    def set_class_name(self, param: Any):\n",
    "        \"\"\"Set the class to the correct one inferred at runtime.\"\"\"\n",
    "        ...\n",
    "\n",
    "    def initialize_parameters(self, input: torch.Tensor) -> None:\n",
    "        \"\"\"Initialize parameters based on the input data.\"\"\"\n",
    "        ...\n",
    "\n",
    "    def _infer_parameters(self, module, input) -> None:\n",
    "        \"\"\"Infer parameters based on the input data.\"\"\"\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Usage:**\n",
    "\n",
    "This mixin class is used as a base for specific classes, such as `LazyConvNd` and `LazyBatchNormNd`, to dynamically configure their behavior and class based on the input data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `LazyConvNd` Class\n",
    "\n",
    "### `LazyConvNd` Class\n",
    "\n",
    "The `LazyConvNd` class is a PyTorch module that extends the `conv.LazyConv1d` class, adding the capability to dynamically set the class and behavior of convolutional layers based on the input shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules import conv\n",
    "\n",
    "class LazyConvNd(_LazyParamDepMixin, conv.LazyConv1d):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usage:**\n",
    "\n",
    "You can use the `LazyConvNd` module to create convolutional layers whose behavior and class are determined at runtime based on the input shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `LazyBatchNormNd` Class\n",
    "\n",
    "### `LazyBatchNormNd` Class\n",
    "\n",
    "The `LazyBatchNormNd` class is a PyTorch module that extends the `batchnorm.LazyBatchNorm1d` class, allowing dynamic configuration of batch normalization layers based on the input shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules import batchnorm\n",
    "\n",
    "class LazyBatchNormNd(_LazyParamDepMixin, batchnorm.LazyBatchNorm1d):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Usage:**\n",
    "\n",
    "You can use the `LazyBatchNormNd` module to create batch normalization layers whose behavior and class are determined at runtime based on the input shape.\n",
    "\n",
    "In this documentation, we have explained the purpose of the provided code and described the usage of the `_LazyParamDepMixin`, `LazyConvNd`, and `LazyBatchNormNd` classes for creating PyTorch modules with dynamic configuration based on the input data. These classes are useful when you need to adapt the behavior and class of neural network layers to different input shapes and dimensions at runtime."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
