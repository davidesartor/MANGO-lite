{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DynamicPolicy Protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### `DynamicPolicy` Protocol\n",
    "\n",
    "The `DynamicPolicy` protocol defines methods to represent the behavior of a dynamic policy in a reinforcement learning environment. It provides a way to select actions based on a command and train the policy using a reward generator and emphasis function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Protocol, Sequence, Callable\n",
    "import numpy.typing as npt\n",
    "import gymnasium as gym\n",
    "\n",
    "class DynamicPolicy(Protocol):\n",
    "    comand_space: gym.spaces.Discrete\n",
    "    action_space: gym.spaces.Discrete\n",
    "\n",
    "    def get_action(self, comand: int, state: npt.NDArray) -> int:\n",
    "        ...\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        transitions: Sequence[tuple[Transition, Transition]],\n",
    "        reward_generator: ActionCompatibility,\n",
    "        emphasis: Callable[[int], float] = lambda _: 1.0,\n",
    "    ) -> None:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Usage:**\n",
    "\n",
    "You can implement concrete dynamic policy classes that adhere to this protocol, providing methods for selecting actions and training the policy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concrete Dynamic Policy Class\n",
    "\n",
    "### `DQnetPolicyMapper`\n",
    "\n",
    "The `DQnetPolicyMapper` class is a concrete implementation of the `DynamicPolicy` protocol. It manages a collection of policies, one for each command, and delegates action selection and training to these policies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(eq=False, slots=True)\n",
    "class DQnetPolicyMapper(DynamicPolicy):\n",
    "    comand_space: gym.spaces.Discrete\n",
    "    action_space: gym.spaces.Discrete\n",
    "\n",
    "    exploration_rate: float = field(init=False, default=1.0, repr=False)\n",
    "    policies: dict[int, Policy] = field(init=False, repr=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        ...\n",
    "        \n",
    "    def get_action(self, comand: int, state: npt.NDArray) -> int:\n",
    "        ...\n",
    "    \n",
    "    def train(\n",
    "        self,\n",
    "        transitions: Sequence[tuple[Transition, Transition]],\n",
    "        reward_gen: ActionCompatibility,\n",
    "        emphasis: Callable[[int], float] = lambda _: 1.0,\n",
    "    ) -> None:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Usage:**\n",
    "\n",
    "You can use the `DQnetPolicyMapper` class to manage multiple policies, each associated with a specific command. This can be useful when dealing with dynamic environments where different policies are needed for different commands.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `__post_init__` Method\n",
    "\n",
    "The `__post_init__` method is called automatically after object initialization. It creates policies for each command using the `DQnetPolicy` class.\n",
    "\n",
    "### `get_action` Method\n",
    "\n",
    "The `get_action` method selects an action based on a command and the current state by delegating the action selection to the corresponding policy.\n",
    "\n",
    "### `train` Method\n",
    "\n",
    "The `train` method trains the policies using a sequence of transitions, a reward generator, and an emphasis function. It trains each policy based on its associated command and transitions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "Here's an example of how to use the `DQnetPolicyMapper` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of DQnetPolicyMapper\n",
    "comand_space = gym.spaces.Discrete(3)\n",
    "action_space = gym.spaces.Discrete(2)\n",
    "policy_mapper = DQnetPolicyMapper(comand_space=comand_space, action_space=action_space)\n",
    "\n",
    "# Generate a sequence of transitions (for illustration purposes)\n",
    "transitions = [(Transition(...), Transition(...)) for _ in range(100)]\n",
    "\n",
    "# Define a reward generator (for illustration purposes)\n",
    "def reward_generator(comand, start_state, next_state):\n",
    "    return float(comand == 1)  # Example: Reward is 1 if comand is 1, else 0\n",
    "\n",
    "# Train the policy mapper\n",
    "policy_mapper.train(transitions, reward_generator)\n",
    "\n",
    "# Get actions based on commands and states\n",
    "comand = 1\n",
    "state = np.array([0.1, 0.2, 0.3])\n",
    "action = policy_mapper.get_action(comand, state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we create an instance of `DQnetPolicyMapper`, generate some transitions, and train the policies within the mapper. We also demonstrate how to use the `get_action` method to select actions based on commands and states."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
