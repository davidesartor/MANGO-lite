{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jax.experimental import host_callback\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import frozen_lake\n",
    "import plotting\n",
    "import qlearning\n",
    "import actions\n",
    "import mangoenv\n",
    "import utils\n",
    "import nets\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_evolution(accuracy_evol, stages_duration):\n",
    "    def smooth(x, w=0.01):\n",
    "        return jnp.convolve(\n",
    "            x, jnp.ones(int(1 + w * len(x))) / int(1 + w * len(x)), mode=\"same\"\n",
    "        )\n",
    "    for run_accuracy in accuracy_evol:\n",
    "        plt.plot(smooth(run_accuracy))\n",
    "\n",
    "    plt.plot(smooth(accuracy_evol.mean(axis=0)), label=\"mean\", color=\"black\", linewidth=3)\n",
    "    for stage_duration in jnp.cumsum(stages_duration):\n",
    "        plt.axvline(stage_duration, color=\"red\")\n",
    "    plt.grid()\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_env(map_scale, p, rng_key):\n",
    "    env = frozen_lake.FrozenLake.make_random(rng_key, map_scale, p)\n",
    "    return env\n",
    "\n",
    "\n",
    "def setup_replay_buffer(env, rng_key, n_rollouts, rollout_steps):\n",
    "    episodes = utils.multi_random_rollout(env, rng_key, rollout_steps, n_rollouts)\n",
    "    replay_buffer = utils.CircularBuffer.store_episodes(episodes)\n",
    "    return replay_buffer\n",
    "\n",
    "\n",
    "def setup_dql_state(env, rng_key, lr, map_scale, cell_scale):\n",
    "    reward_fn = actions.get_reward_fn(cell_scale)\n",
    "    beta_fn = actions.get_beta_fn(cell_scale)\n",
    "    qnet = nets.MultiTaskQnet(\n",
    "        n_actions=env.action_space.n,\n",
    "        n_comands=5,\n",
    "        map_shape=(2**map_scale, 2**map_scale),\n",
    "        cell_shape=(2**cell_scale, 2**cell_scale),\n",
    "    )\n",
    "    dql_state = qlearning.MultiDQLTrainState.create(\n",
    "        rng_key, qnet, env, reward_fn=reward_fn, beta_fn=beta_fn, lr=lr\n",
    "    )\n",
    "    return dql_state\n",
    "\n",
    "\n",
    "def eval_policy(env, dql_state, rng_key, episodes, steps):\n",
    "    def eval_single(rng_key):\n",
    "        transitions = dql_state.greedy_rollout(env, rng_key, steps)\n",
    "        episodes = jnp.clip(transitions.done.sum(), a_min=1)\n",
    "        rewards = transitions.reward.sum()\n",
    "        return rewards, episodes\n",
    "\n",
    "    rewards, episodes = jax.vmap(eval_single)(jax.random.split(rng_key, episodes))\n",
    "    return rewards.sum() / episodes.sum()\n",
    "\n",
    "\n",
    "def train_stage(rng_key, env, dql_state, replay_buffer, n_train_iter, batch_size):\n",
    "    pbar = tqdm(total=n_train_iter, desc=\"Training\")\n",
    "\n",
    "    def train_step(dql_state, rng_key):\n",
    "        rng_train, rng_eval = host_callback.id_tap(\n",
    "            lambda a, t: pbar.update(1), jax.random.split(rng_key)\n",
    "        )\n",
    "        dql_state = dql_state.update_params(replay_buffer.sample(rng_train, batch_size))\n",
    "        accuracy = eval_policy(env, dql_state, rng_eval, episodes=64, steps=5)\n",
    "        return dql_state, accuracy\n",
    "\n",
    "    rng_steps = jax.random.split(rng_key, n_train_iter)\n",
    "    dql_state, accuracy_evolution = jax.lax.scan(train_step, dql_state, rng_steps)\n",
    "    return dql_state, accuracy_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_objective_fn(map_scale, cell_scales, max_steps, p, n_sims=16):\n",
    "    multi_env_setup = jax.jit(\n",
    "        jax.vmap(setup_env, in_axes=(None, None, 0)),\n",
    "        static_argnames=(\"map_scale\", \"p\"),\n",
    "    )\n",
    "    multi_replay_buffer_setup = jax.jit(\n",
    "        jax.vmap(setup_replay_buffer, in_axes=(0, 0, None, None)),\n",
    "        static_argnames=(\"n_rollouts\", \"rollout_steps\"),\n",
    "    )\n",
    "    multi_dql_state_setup = jax.jit(\n",
    "        jax.vmap(setup_dql_state, in_axes=(0, 0, None, None, None)),\n",
    "        static_argnames=(\"lr\", \"map_scale\", \"cell_scale\"),\n",
    "    )\n",
    "    multi_train_stage = jax.jit(\n",
    "        jax.vmap(train_stage, in_axes=(0, 0, 0, 0, None, None)),\n",
    "        static_argnames=(\"n_train_iter\", \"batch_size\"),\n",
    "    )\n",
    "\n",
    "    def run_stage(rng_key, envs, cell_scale, lr, train_iter, batch_size, n_rollouts, rollout_steps):\n",
    "        rng_rollout, rng_init, rng_train = jax.random.split(rng_key, 3)\n",
    "        rng_rollout = jax.random.split(rng_rollout, n_sims)\n",
    "        rng_init = jax.random.split(rng_init, n_sims)\n",
    "        rng_train = jax.random.split(rng_train, n_sims)\n",
    "\n",
    "        replay_buffers = multi_replay_buffer_setup(envs, rng_rollout, n_rollouts, rollout_steps)\n",
    "        dql_states = multi_dql_state_setup(envs, rng_init, lr, map_scale, cell_scale)\n",
    "        dql_states, accuracy_evol = multi_train_stage(\n",
    "            rng_train, envs, dql_states, replay_buffers, train_iter, batch_size\n",
    "        )\n",
    "        return dql_states, accuracy_evol\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> jnp.float_:\n",
    "        # global hyperparameters\n",
    "        lr = 10 ** trial.suggest_float(\"log_lr\", -5, -3, step=0.5)\n",
    "        batch_size = 2 ** trial.suggest_int(\"log_batch_size\", 10, 10)\n",
    "        rollout_steps = 2 ** trial.suggest_int(\"log_rollout_steps\", 4, 10)  # 16 to 1024\n",
    "        total_train_iter = max_steps // batch_size\n",
    "\n",
    "        # attributes\n",
    "        seed = trial.number\n",
    "        trial.set_user_attr(\"max_steps\", max_steps)\n",
    "        trial.set_user_attr(\"total_train_iter\", total_train_iter)\n",
    "\n",
    "        # setup rng\n",
    "        rng_key = jax.random.PRNGKey(seed)\n",
    "        rng_env, rng_stages = jax.random.split(rng_key, 2)\n",
    "        rng_env = jax.random.split(rng_env, n_sims)\n",
    "        rng_stages = jax.random.split(rng_stages, len(cell_scales))\n",
    "\n",
    "        # sim setup\n",
    "        train_iter_budget = total_train_iter\n",
    "        stages_accuracy = []\n",
    "\n",
    "        envs = multi_env_setup(map_scale, p, rng_env)\n",
    "        for cell_scale, rng_stage in zip(cell_scales[:-1], rng_stages[:-1]):\n",
    "            # inner stage hyperparameters\n",
    "            train_iter = 2 ** trial.suggest_int(\n",
    "                f\"log_train_iter_{cell_scale}\", 4, np.ceil(np.log2(train_iter_budget)) - 1\n",
    "            )\n",
    "            train_iter_budget -= train_iter\n",
    "            n_rollouts = train_iter * batch_size // rollout_steps\n",
    "\n",
    "            # train inner stage\n",
    "            dql_states, accuracy_evol = run_stage(\n",
    "                rng_stage, envs, cell_scale, lr, train_iter, batch_size, n_rollouts, rollout_steps\n",
    "            )\n",
    "            envs = mangoenv.MangoEnv(envs, dql_states, max_steps=8)\n",
    "            stages_accuracy.append(accuracy_evol)\n",
    "\n",
    "        # final stage hyperparameters\n",
    "        cell_scale = cell_scales[-1]\n",
    "        rng_stage = rng_stages[-1]\n",
    "        train_iter = train_iter_budget\n",
    "        n_rollouts = train_iter * batch_size // rollout_steps\n",
    "\n",
    "        # train final stage\n",
    "        dql_states, accuracy_evol = run_stage(\n",
    "            rng_stage, envs, cell_scale, lr, train_iter, batch_size, n_rollouts, rollout_steps\n",
    "        )\n",
    "        stages_accuracy.append(accuracy_evol)\n",
    "\n",
    "        accuracy_evol = jnp.concatenate(stages_accuracy, axis=-1)\n",
    "        plot_accuracy_evolution(accuracy_evol, [stage_acc.shape[-1] for stage_acc in stages_accuracy])\n",
    "        trial.set_user_attr(f\"accuracy_evol\", np.asarray(accuracy_evol).tolist())\n",
    "        return accuracy_evol.mean()\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-02 01:46:14,417] Using an existing study with name 'mango' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82eb7367cd4447abba70d6c0d5a5e182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stage 1 with 256 iterations\n",
      "Rollouts: 8192\n",
      "Rollout steps: 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268fb31f0cbd45628ffe849fb4d05dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Random Rollout:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7aa8f0006ce41d295010db64b67f007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9987d23e781444f8b7a64d7658133bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Greedy Rollout:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950a6b36ef9242aea95b3cfaed6e7cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Random Rollout:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_scale = 2\n",
    "cell_scales = (1,2)\n",
    "p = 0.5\n",
    "max_steps = 1024*1024\n",
    "\n",
    "storage_path = f\"sqlite:///optuna_studies/{2**map_scale}x{2**map_scale}_p_{p}_stages={list(cell_scales)}.db\"\n",
    "study = optuna.create_study(\n",
    "    study_name=f\"mango\",\n",
    "    storage=storage_path,\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    ")\n",
    "study.optimize(\n",
    "    get_objective_fn(map_scale, cell_scales, max_steps, p, n_sims=16),\n",
    "    n_trials=2,\n",
    "    show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_scale = 2\n",
    "cell_scales = (2,)\n",
    "storage_path = f\"{2**map_scale}x{2**map_scale}_stages={list(cell_scales)}.db\"\n",
    "\n",
    "cmd = f\"optuna-dashboard 'sqlite:///optuna_studies/{storage_path}'\"\n",
    "#get_ipython().system(cmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
