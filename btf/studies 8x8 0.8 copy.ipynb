{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '0.2'\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jax.experimental import host_callback\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import frozen_lake\n",
    "import plotting\n",
    "import qlearning\n",
    "import actions\n",
    "import mangoenv\n",
    "import utils\n",
    "import nets\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_evolution(accuracy_evol, stages_duration):\n",
    "    def smooth(x, w=0.01):\n",
    "        filter = jnp.ones(int(1 + w * len(x)))\n",
    "        smoothed = jnp.convolve(x, filter / filter.sum(), mode=\"full\")\n",
    "        return smoothed[:len(x)]\n",
    "\n",
    "    for run_accuracy in accuracy_evol:\n",
    "        plt.plot(smooth(run_accuracy))\n",
    "\n",
    "    plt.plot(smooth(accuracy_evol.mean(axis=0)), label=\"mean\", color=\"black\", linewidth=3)\n",
    "    for stage_duration in jnp.cumsum(jnp.array(stages_duration)):\n",
    "        plt.axvline(stage_duration, color=\"red\")\n",
    "    plt.grid()\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_env(map_scale, p, rng_key):\n",
    "    env = frozen_lake.FrozenLake.make_random(rng_key, map_scale, p)\n",
    "    return env\n",
    "\n",
    "\n",
    "def setup_replay_buffer(env, rng_key, n_rollouts, rollout_steps):\n",
    "    episodes = utils.multi_random_rollout(env, rng_key, rollout_steps, n_rollouts)\n",
    "    replay_buffer = utils.CircularBuffer.store_episodes(episodes)\n",
    "    return replay_buffer\n",
    "\n",
    "\n",
    "def setup_dql_state(env, rng_key, lr, map_scale, cell_scale):\n",
    "    reward_fn = actions.get_reward_fn(cell_scale)\n",
    "    beta_fn = actions.get_beta_fn(cell_scale)\n",
    "    qnet = nets.MultiTaskQnet(\n",
    "        n_actions=env.action_space.n,\n",
    "        n_comands=5,\n",
    "        map_shape=(2**map_scale, 2**map_scale),\n",
    "        cell_shape=(2**cell_scale, 2**cell_scale),\n",
    "    )\n",
    "    dql_state = qlearning.MultiDQLTrainState.create(\n",
    "        rng_key, qnet, env, reward_fn=reward_fn, beta_fn=beta_fn, lr=lr\n",
    "    )\n",
    "    return dql_state\n",
    "\n",
    "\n",
    "def eval_policy(env, dql_state, rng_key, episodes, steps):\n",
    "    def eval_single(rng_key):\n",
    "        transitions = dql_state.greedy_rollout(env, rng_key, steps)\n",
    "        episodes = jnp.clip(transitions.done.sum(), a_min=1)\n",
    "        rewards = transitions.reward.sum()\n",
    "        return rewards, episodes\n",
    "\n",
    "    rewards, episodes = jax.vmap(eval_single)(jax.random.split(rng_key, episodes))\n",
    "    return rewards.sum() / episodes.sum()\n",
    "\n",
    "\n",
    "def train_stage(rng_key, env, dql_state, replay_buffer, n_train_iter, batch_size, eval_steps):\n",
    "    pbar = tqdm(total=n_train_iter, desc=\"Training\")\n",
    "\n",
    "    def train_step(dql_state, rng_key):\n",
    "        rng_train, rng_eval = host_callback.id_tap(\n",
    "            lambda a, t: pbar.update(1), jax.random.split(rng_key)\n",
    "        )\n",
    "        dql_state = dql_state.update_params(replay_buffer.sample(rng_train, batch_size))\n",
    "        accuracy = eval_policy(env, dql_state, rng_eval, episodes=8, steps=eval_steps)\n",
    "        return dql_state, accuracy\n",
    "\n",
    "    rng_steps = jax.random.split(rng_key, n_train_iter)\n",
    "    dql_state, accuracy_evolution = jax.lax.scan(train_step, dql_state, rng_steps)\n",
    "    return dql_state, accuracy_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_objective_fn(map_scale, cell_scales, max_steps, p, train_minicycles=16, n_sims=16):\n",
    "    multi_env_setup = jax.jit(\n",
    "        jax.vmap(setup_env, in_axes=(None, None, 0)),\n",
    "        static_argnames=(\"map_scale\", \"p\"),\n",
    "    )\n",
    "    multi_replay_buffer_setup = jax.jit(\n",
    "        jax.vmap(setup_replay_buffer, in_axes=(0, 0, None, None)),\n",
    "        static_argnames=(\"n_rollouts\", \"rollout_steps\"),\n",
    "    )\n",
    "    multi_dql_state_setup = jax.jit(\n",
    "        jax.vmap(setup_dql_state, in_axes=(0, 0, None, None, None)),\n",
    "        static_argnames=(\"lr\", \"map_scale\", \"cell_scale\"),\n",
    "    )\n",
    "    multi_train_stage = jax.jit(\n",
    "        jax.vmap(train_stage, in_axes=(0, 0, 0, 0, None, None, None)),\n",
    "        static_argnames=(\"n_train_iter\", \"batch_size\", \"eval_steps\"),\n",
    "    )\n",
    "\n",
    "    def run_stage(\n",
    "        envs, rng_key, cell_scale, lr, n_cycles, train_iter, batch_size, n_rollouts, rollout_steps, eval_steps\n",
    "    ):\n",
    "        rng_init, rng_cycles = jax.random.split(rng_key)\n",
    "        rng_init = jax.random.split(rng_init, n_sims)\n",
    "        rng_cycles = jax.random.split(rng_cycles, n_cycles)\n",
    "\n",
    "        dql_states = multi_dql_state_setup(envs, rng_init, lr, map_scale, cell_scale)\n",
    "        cycle_accuracy = []\n",
    "\n",
    "        for rng_cycle in tqdm(rng_cycles, desc=f\"Training {cell_scale}\"):\n",
    "            # setup rngs\n",
    "            rng_rollout, rng_train = jax.random.split(rng_cycle)\n",
    "            rng_rollout = jax.random.split(rng_rollout, n_sims)\n",
    "            rng_train = jax.random.split(rng_train, n_sims)\n",
    "\n",
    "            # train stage\n",
    "            replay_buffers = multi_replay_buffer_setup(envs, rng_rollout, n_rollouts, rollout_steps)\n",
    "            dql_states, accuracy_evol = multi_train_stage(\n",
    "                rng_train, envs, dql_states, replay_buffers, train_iter, batch_size, eval_steps\n",
    "            )\n",
    "            cycle_accuracy.append(accuracy_evol)\n",
    "        return dql_states, jnp.concatenate(cycle_accuracy, axis=-1)\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> jnp.float_:\n",
    "        # global hyperparameters\n",
    "        batch_size = 2 ** trial.suggest_int(\"log_batch_size\", 10, 10)\n",
    "        rollout_steps = 2 ** trial.suggest_int(\"log_rollout_steps\", 3, 3)\n",
    "        total_train_iter = max_steps // batch_size\n",
    "        train_iter = total_train_iter // train_minicycles\n",
    "        n_rollouts = train_iter * batch_size // rollout_steps\n",
    "\n",
    "        # attributes\n",
    "        seed = trial.number\n",
    "        trial.set_user_attr(\"max_steps\", max_steps)\n",
    "        trial.set_user_attr(\"cycle_train_iter\", train_iter)\n",
    "\n",
    "        # setup rng\n",
    "        rng_key = jax.random.PRNGKey(seed)\n",
    "        rng_env, rng_stages = jax.random.split(rng_key, 2)\n",
    "        rng_env = jax.random.split(rng_env, n_sims)\n",
    "        rng_stages = jax.random.split(rng_stages, len(cell_scales))\n",
    "\n",
    "        # sim setup\n",
    "        train_cycle_budget = train_minicycles\n",
    "        stages_accuracy = []\n",
    "        envs = multi_env_setup(map_scale, p, rng_env)\n",
    "\n",
    "        for prev_cell_scale, cell_scale, rng_stage in zip(\n",
    "            [0] + list(cell_scales[:-2]), cell_scales[:-1], rng_stages[:-1]\n",
    "        ):\n",
    "            # inner stage hyperparameters\n",
    "            lr = 10 ** trial.suggest_float(f\"log_lr_{cell_scale}\", -5, -3, step=0.5)\n",
    "            train_cycles = trial.suggest_int(\n",
    "                f\"train_cycles_{cell_scale}\", 1, train_cycle_budget - len(cell_scales)\n",
    "            )\n",
    "            train_cycle_budget -= train_cycles\n",
    "            eval_steps = (2 ** (cell_scale - prev_cell_scale)) ** 2\n",
    "\n",
    "            # train inner stage\n",
    "            dql_states, accuracy_evol = run_stage(\n",
    "                envs,\n",
    "                rng_stage,\n",
    "                cell_scale,\n",
    "                lr,\n",
    "                train_cycles,\n",
    "                train_iter,\n",
    "                batch_size,\n",
    "                n_rollouts,\n",
    "                rollout_steps,\n",
    "                eval_steps,\n",
    "            )\n",
    "\n",
    "            # setup next stage and store results\n",
    "            stages_accuracy.append(accuracy_evol)\n",
    "            envs = mangoenv.MangoEnv(envs, dql_states, max_steps=5)\n",
    "            n_rollouts = n_rollouts // 4\n",
    "\n",
    "            # report intermediate results\n",
    "            # accuracy_evol = jnp.concatenate(stages_accuracy, axis=-1)\n",
    "            # trial.report(accuracy_evol.mean(), step=accuracy_evol.shape[-1])\n",
    "            # if trial.should_prune():\n",
    "            #     raise optuna.TrialPruned()\n",
    "\n",
    "        # final stage hyperparameters\n",
    "        prev_cell_scale = ([0]+list(cell_scales))[-2]\n",
    "        cell_scale = cell_scales[-1]\n",
    "        rng_stage = rng_stages[-1]\n",
    "        train_cycles = trial.suggest_int(\n",
    "            f\"train_cycles_{cell_scale}\", train_cycle_budget, train_cycle_budget\n",
    "        )\n",
    "        lr = 10 ** trial.suggest_float(f\"log_lr_{cell_scale}\", -5, -3, step=0.5)\n",
    "        eval_steps = (2 ** (cell_scale - prev_cell_scale)) ** 2\n",
    "\n",
    "        # train final stage\n",
    "        dql_states, accuracy_evol = run_stage(\n",
    "            envs,\n",
    "            rng_stage,\n",
    "            cell_scale,\n",
    "            lr,\n",
    "            train_cycles,\n",
    "            train_iter,\n",
    "            batch_size,\n",
    "            n_rollouts,\n",
    "            rollout_steps,\n",
    "            eval_steps,\n",
    "        )\n",
    "        stages_accuracy.append(accuracy_evol)\n",
    "\n",
    "        accuracy_evol = jnp.concatenate(stages_accuracy, axis=-1)\n",
    "        plot_accuracy_evolution(\n",
    "            accuracy_evol, [stage_acc.shape[-1] for stage_acc in stages_accuracy]\n",
    "        )\n",
    "        trial.set_user_attr(f\"accuracy_evol\", np.asarray(accuracy_evol).tolist())\n",
    "        accuracy = (accuracy_evol.mean(axis=0) - accuracy_evol.std(axis=0)).mean()\n",
    "        return accuracy\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-02 06:50:28,454] Using an existing study with name 'mango' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebd22b09c5e4ff88b456ab7fad03e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188463267e814f9aa7f70f1eabd8da6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training 3:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987ff24bd4514c58ba09c8f434599513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Random Rollout:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242b922a640f481188ee186d9d7125b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc014dc5558549918eabbcf170108ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Greedy Rollout:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_scale = 3\n",
    "cell_scales = (3,)\n",
    "p = 0.5\n",
    "max_steps = 1024*1024*8\n",
    "\n",
    "storage_path = f\"sqlite:///optuna_studies/{2**map_scale}x{2**map_scale}_p_{p}_stages={list(cell_scales)}.db\"\n",
    "study = optuna.create_study(\n",
    "    study_name=f\"mango\",\n",
    "    storage=storage_path,\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    ")\n",
    "study.optimize(\n",
    "    get_objective_fn(map_scale, cell_scales, max_steps, p),\n",
    "    n_trials=32,\n",
    "    show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_scale = 2\n",
    "cell_scales = (2,)\n",
    "storage_path = f\"{2**map_scale}x{2**map_scale}_stages={list(cell_scales)}.db\"\n",
    "\n",
    "cmd = f\"optuna-dashboard 'sqlite:///optuna_studies/{storage_path}'\"\n",
    "#get_ipython().system(cmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
